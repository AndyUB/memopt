2025-11-27 16:15:30,073 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=None, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,129 __main__ INFO Step 0, Loss: 0.9563060998916626, Step success: True
2025-11-27 16:15:31,132 __main__ INFO Step 1, Loss: 0.9187057018280029, Step success: True
2025-11-27 16:15:31,134 __main__ INFO Step 2, Loss: 0.8838024139404297, Step success: True
2025-11-27 16:15:31,137 __main__ INFO Step 3, Loss: 0.8513141870498657, Step success: True
2025-11-27 16:15:31,139 __main__ INFO Step 4, Loss: 0.8208171129226685, Step success: True
2025-11-27 16:15:31,139 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=None, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,146 __main__ INFO Step 0, Loss: 0.956305742263794, Step success: True
2025-11-27 16:15:31,147 __main__ INFO Step 1, Loss: 0.9187220335006714, Step success: True
2025-11-27 16:15:31,148 __main__ INFO Step 2, Loss: 0.8838056325912476, Step success: True
2025-11-27 16:15:31,149 __main__ INFO Step 3, Loss: 0.8513520359992981, Step success: True
2025-11-27 16:15:31,151 __main__ INFO Step 4, Loss: 0.8207629323005676, Step success: True
2025-11-27 16:15:31,151 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=None, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,155 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,157 __main__ INFO Step 1, Loss: 0.91845703125, Step success: True
2025-11-27 16:15:31,160 __main__ INFO Step 2, Loss: 0.8837890625, Step success: True
2025-11-27 16:15:31,162 __main__ INFO Step 3, Loss: 0.85107421875, Step success: True
2025-11-27 16:15:31,165 __main__ INFO Step 4, Loss: 0.82080078125, Step success: True
2025-11-27 16:15:31,165 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=None, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,168 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,169 __main__ INFO Step 1, Loss: 0.91845703125, Step success: True
2025-11-27 16:15:31,171 __main__ INFO Step 2, Loss: 0.8837890625, Step success: True
2025-11-27 16:15:31,173 __main__ INFO Step 3, Loss: 0.85107421875, Step success: True
2025-11-27 16:15:31,175 __main__ INFO Step 4, Loss: 0.82080078125, Step success: True
2025-11-27 16:15:31,175 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=8, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,179 __main__ INFO Step 0, Loss: 0.9563060998916626, Step success: True
2025-11-27 16:15:31,181 __main__ INFO Step 1, Loss: 0.918705940246582, Step success: True
2025-11-27 16:15:31,184 __main__ INFO Step 2, Loss: 0.8838024139404297, Step success: True
2025-11-27 16:15:31,186 __main__ INFO Step 3, Loss: 0.8513164520263672, Step success: True
2025-11-27 16:15:31,189 __main__ INFO Step 4, Loss: 0.8208177089691162, Step success: True
2025-11-27 16:15:31,189 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=8, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,191 __main__ INFO Step 0, Loss: 0.956305742263794, Step success: True
2025-11-27 16:15:31,192 __main__ INFO Step 1, Loss: 0.9187220335006714, Step success: True
2025-11-27 16:15:31,194 __main__ INFO Step 2, Loss: 0.8838056325912476, Step success: True
2025-11-27 16:15:31,195 __main__ INFO Step 3, Loss: 0.8513520359992981, Step success: True
2025-11-27 16:15:31,196 __main__ INFO Step 4, Loss: 0.8207629323005676, Step success: True
2025-11-27 16:15:31,196 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=8, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,200 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,203 __main__ INFO Step 1, Loss: 0.91845703125, Step success: True
2025-11-27 16:15:31,205 __main__ INFO Step 2, Loss: 0.8837890625, Step success: True
2025-11-27 16:15:31,208 __main__ INFO Step 3, Loss: 0.85107421875, Step success: True
2025-11-27 16:15:31,210 __main__ INFO Step 4, Loss: 0.82080078125, Step success: True
2025-11-27 16:15:31,210 __main__ INFO === dtype=torch.float16, use_master_copy=True, loss_scale=8, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,213 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,215 __main__ INFO Step 1, Loss: 0.91845703125, Step success: True
2025-11-27 16:15:31,217 __main__ INFO Step 2, Loss: 0.8837890625, Step success: True
2025-11-27 16:15:31,219 __main__ INFO Step 3, Loss: 0.85107421875, Step success: True
2025-11-27 16:15:31,221 __main__ INFO Step 4, Loss: 0.82080078125, Step success: True
2025-11-27 16:15:31,221 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=None, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,224 __main__ INFO Step 0, Loss: 0.9561067819595337, Step success: True
2025-11-27 16:15:31,271 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,271 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,272 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,273 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,273 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,274 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,274 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,274 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,276 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,276 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,277 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,278 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,278 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,278 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,279 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,279 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,280 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,281 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,282 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,282 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,283 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,283 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,283 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,283 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,285 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,285 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,286 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,287 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,287 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,287 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,287 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,287 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,288 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=None, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,291 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,292 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,292 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,293 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,293 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,293 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,293 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,294 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,294 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,295 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,295 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,296 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,296 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,296 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,296 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,296 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,297 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,298 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,298 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,299 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,299 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,299 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,299 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,300 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,300 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,301 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,301 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,302 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,302 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,302 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,302 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,302 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,303 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,303 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=None, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,306 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,307 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,308 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,309 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,309 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,310 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,310 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,310 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,310 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,312 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,312 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,313 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,313 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,314 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,314 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,314 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,314 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,316 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,317 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,317 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,318 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,318 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,319 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,319 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,319 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,320 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,321 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,322 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,322 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,322 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,323 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,323 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,323 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,323 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=None, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,326 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,327 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,327 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,328 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,328 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,328 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,328 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,328 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,329 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,330 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,330 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,331 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,331 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,331 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,331 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,331 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,331 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,333 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,333 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,334 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,334 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,334 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,334 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,334 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,334 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,336 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,336 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,336 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,337 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,337 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,337 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,337 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,337 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,337 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=8, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,341 __main__ INFO Step 0, Loss: 0.9561067819595337, Step success: True
2025-11-27 16:15:31,342 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,343 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,344 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,344 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,345 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,345 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,345 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,345 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,347 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,347 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,348 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,349 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,349 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,349 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,349 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,350 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,351 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,352 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,352 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,353 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,353 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,354 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,354 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,354 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,356 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,356 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,357 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,357 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,358 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,358 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,358 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,358 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,358 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=8, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,361 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,362 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,363 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,363 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,363 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,364 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,364 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,364 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,364 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,365 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,366 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,366 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,366 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,367 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,367 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,367 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,367 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,368 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,369 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,369 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,369 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,370 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,370 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,370 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,370 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,371 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,372 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,372 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,372 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,373 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,373 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,373 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,373 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,373 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=8, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,376 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,378 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,378 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,379 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,380 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,380 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,380 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,380 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,381 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,382 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,383 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,384 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,384 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,384 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,385 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,385 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,385 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,387 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,387 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,388 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,388 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,389 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,389 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,389 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,389 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,391 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,391 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,392 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.float16)
2025-11-27 16:15:31,393 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,393 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,393 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], device='cuda:0', dtype=torch.float16)
2025-11-27 16:15:31,394 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,394 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,394 __main__ INFO === dtype=torch.float16, use_master_copy=False, loss_scale=8, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,396 __main__ INFO Step 0, Loss: 0.9560546875, Step success: True
2025-11-27 16:15:31,398 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,398 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,398 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,399 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,399 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,399 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,399 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,399 __main__ INFO Step 1, Loss: nan, Step success: False
2025-11-27 16:15:31,401 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,401 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,401 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,402 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,402 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,402 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,402 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,402 __main__ INFO Step 2, Loss: nan, Step success: False
2025-11-27 16:15:31,404 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,404 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,404 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,405 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,405 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,405 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,405 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,405 __main__ INFO Step 3, Loss: nan, Step success: False
2025-11-27 16:15:31,407 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,407 memopt.mixprec WARNING Overflow detected in gradient of parameter `0.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float16)
2025-11-27 16:15:31,407 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.weight`: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float16)
2025-11-27 16:15:31,408 memopt.mixprec WARNING Overflow detected in gradient of parameter `2.bias`: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       dtype=torch.float16)
2025-11-27 16:15:31,408 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.weight`: tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float16)
2025-11-27 16:15:31,408 memopt.mixprec WARNING Overflow detected in gradient of parameter `4.bias`: tensor([nan], dtype=torch.float16)
2025-11-27 16:15:31,408 memopt.mixprec WARNING Skipping optimizer step due to gradient overflow. Gradients have been cleared.
2025-11-27 16:15:31,408 __main__ INFO Step 4, Loss: nan, Step success: False
2025-11-27 16:15:31,408 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=None, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,446 __main__ INFO Step 0, Loss: 0.9566010236740112, Step success: True
2025-11-27 16:15:31,449 __main__ INFO Step 1, Loss: 0.9188321828842163, Step success: True
2025-11-27 16:15:31,451 __main__ INFO Step 2, Loss: 0.8840764164924622, Step success: True
2025-11-27 16:15:31,454 __main__ INFO Step 3, Loss: 0.8513751029968262, Step success: True
2025-11-27 16:15:31,457 __main__ INFO Step 4, Loss: 0.8209503889083862, Step success: True
2025-11-27 16:15:31,457 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=None, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,461 __main__ INFO Step 0, Loss: 0.956305742263794, Step success: True
2025-11-27 16:15:31,463 __main__ INFO Step 1, Loss: 0.9187220335006714, Step success: True
2025-11-27 16:15:31,465 __main__ INFO Step 2, Loss: 0.8838056325912476, Step success: True
2025-11-27 16:15:31,467 __main__ INFO Step 3, Loss: 0.8513520359992981, Step success: True
2025-11-27 16:15:31,468 __main__ INFO Step 4, Loss: 0.8207629323005676, Step success: True
2025-11-27 16:15:31,468 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=None, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,474 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,478 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,481 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,485 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,488 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,488 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=None, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,493 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,495 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,497 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,499 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,501 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,501 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=8, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,502 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,505 __main__ INFO Step 0, Loss: 0.9566010236740112, Step success: True
2025-11-27 16:15:31,508 __main__ INFO Step 1, Loss: 0.9188321828842163, Step success: True
2025-11-27 16:15:31,511 __main__ INFO Step 2, Loss: 0.8840764164924622, Step success: True
2025-11-27 16:15:31,514 __main__ INFO Step 3, Loss: 0.8513751029968262, Step success: True
2025-11-27 16:15:31,517 __main__ INFO Step 4, Loss: 0.8209503889083862, Step success: True
2025-11-27 16:15:31,517 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=8, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,517 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,519 __main__ INFO Step 0, Loss: 0.956305742263794, Step success: True
2025-11-27 16:15:31,520 __main__ INFO Step 1, Loss: 0.9187220335006714, Step success: True
2025-11-27 16:15:31,522 __main__ INFO Step 2, Loss: 0.8838056325912476, Step success: True
2025-11-27 16:15:31,523 __main__ INFO Step 3, Loss: 0.8513520359992981, Step success: True
2025-11-27 16:15:31,524 __main__ INFO Step 4, Loss: 0.8207629323005676, Step success: True
2025-11-27 16:15:31,525 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=8, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,525 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,529 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,531 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,534 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,537 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,540 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,540 __main__ INFO === dtype=torch.bfloat16, use_master_copy=True, loss_scale=8, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,540 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,543 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,545 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,547 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,549 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,551 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,551 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=None, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,555 __main__ INFO Step 0, Loss: 0.9603171944618225, Step success: True
2025-11-27 16:15:31,557 __main__ INFO Step 1, Loss: 0.9227805137634277, Step success: True
2025-11-27 16:15:31,560 __main__ INFO Step 2, Loss: 0.8861685991287231, Step success: True
2025-11-27 16:15:31,562 __main__ INFO Step 3, Loss: 0.8538992404937744, Step success: True
2025-11-27 16:15:31,564 __main__ INFO Step 4, Loss: 0.8229082822799683, Step success: True
2025-11-27 16:15:31,564 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=None, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,567 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,569 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,571 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,573 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,575 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,575 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=None, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,578 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,580 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,582 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,585 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,587 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,587 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=None, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,590 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,591 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,593 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,595 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,597 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,597 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=8, use_autocast=True, device=cuda ===
2025-11-27 16:15:31,598 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,601 __main__ INFO Step 0, Loss: 0.9603171944618225, Step success: True
2025-11-27 16:15:31,603 __main__ INFO Step 1, Loss: 0.9227805137634277, Step success: True
2025-11-27 16:15:31,605 __main__ INFO Step 2, Loss: 0.8861685991287231, Step success: True
2025-11-27 16:15:31,608 __main__ INFO Step 3, Loss: 0.8538992404937744, Step success: True
2025-11-27 16:15:31,610 __main__ INFO Step 4, Loss: 0.8229082822799683, Step success: True
2025-11-27 16:15:31,610 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=8, use_autocast=True, device=cpu ===
2025-11-27 16:15:31,611 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,613 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,615 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,617 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,619 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,621 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,621 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=8, use_autocast=False, device=cuda ===
2025-11-27 16:15:31,622 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,625 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,627 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,629 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,631 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,634 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
2025-11-27 16:15:31,634 __main__ INFO === dtype=torch.bfloat16, use_master_copy=False, loss_scale=8, use_autocast=False, device=cpu ===
2025-11-27 16:15:31,634 memopt.mixprec WARNING Loss scaling is typically not needed for BF16.
2025-11-27 16:15:31,637 __main__ INFO Step 0, Loss: 0.9609375, Step success: True
2025-11-27 16:15:31,639 __main__ INFO Step 1, Loss: 0.921875, Step success: True
2025-11-27 16:15:31,641 __main__ INFO Step 2, Loss: 0.88671875, Step success: True
2025-11-27 16:15:31,643 __main__ INFO Step 3, Loss: 0.85546875, Step success: True
2025-11-27 16:15:31,645 __main__ INFO Step 4, Loss: 0.82421875, Step success: True
